---
title: 'Using R: An Introduction to Data Wrangling'
author: "Joseph R. Stinziano"
date: "12/02/2020"
output: html_document
---

#Types of objects in R
R is an object-oriented programming language. There are 
different types of objects, including dataframes, lists,
vectors, matrices, arrays, etc. A lot of analyses in
biology can be conducted working mostly with dataframes,
lists and vectors. It is important to keep track of object
types in R, since how you work with each type of object
varies.

There are different classes of variables as well, including
doubles (integers and numeric), characters, factors, POSIX
(useful for dates and times), etc.
```{r}
#Create a vector from 1 to 10
#Note that the colon : creates a sequence
a <- 1:10

#Check its class
class(a)

#Create a string
#Note the concanetate function c(), and the repeat function
#rep()
b <- c(rep("a", 5), rep("b", 5))

#Check its class
class(b)

#Next we can take vectors a and b to turn them into a
#dataframe. Note the as.data.frame() function and the
#cbind() function - cbind = column bind, to bind rows
#use rbind() for "row bind"
d <- as.data.frame(cbind(a, b), stringsAsFactors = FALSE)

#Check its class
class(d)

#Create summary
summary(d)
#Notice that "a" is a character, but should be a number
#Let's fix that
d$a <- as.numeric(d$a)
#Note that the "$" extracts a variable from a dataframe
#We can also use:
d[, "a"]

#Create a boxplot
boxplot(a ~ b, data = d)
#Notice the "~" - this is used for specifying formulas
#This will make more sense when we get to the stats

#What happens if we do not use as.data.frame?
d <- cbind(a, b)
class(d)
summary(d)
#Note that if we try to extract a variable from a matrix
#like we do for a dataframe, it doesn't work!
d$a

#Instead we extract the column like this:
d[, "a"]

#To extract a row, we can use:
d[1, ]
#Notice how one method of extracting information is more
#general than others? In some cases you may want to use
#a specific method (like "$") to force an error if the
#object types are incorrect!

#What about factors?
d <- as.data.frame(cbind(a, b), stringsAsFactors = FALSE)
d$b <- as.factor(d$b)
d$b
summary(d$b)
levels(d$b)
#Note that factors are stored as dummy numbers referring
#to a character level. To convert from a factor to a
#character, use:
d$b <- levels(d$b)[d$b]
```

#Importing data into R
Unless you are doing specialized analyses, most of your data
will be in a delimited text format, including tab-delimited,
and comma-separated values (csv). In some case you will need
to read in an Excel file - luckily there are functions for
that as well.

When reading in files, it is best to set stringsasFactors as
FALSE to avoid the issue of have to convert data from a factor
to a character.

R looks for files based on the working directory (i.e. file
folder). Before importing data, it is important to confirm
that the working directory is correct.
```{r}
#Get the working directory
getwd()

#This line is for an example of how to set working directory
WD <- getwd()

#You can set the working directory with:
setwd(WD)

#It is easiest to read data into R when it is in the .csv format
data <- read.csv("light_responses.csv", stringsAsFactors = FALSE)

#If your data are in a tab-limited format, use:
data <- read.delim("poplar_light_tab_delim", sep = "\t", 
                   stringsAsFactors = FALSE)

#If your data are in an Excel format (xls, xlsx) use:
library(readxl)
data <- read_excel("light_responses.xlsx")
#In general, it is best to use .csv format for your data if you
#have a choice between xls and csv formats

```

#Rearranging data in R, subsetting, creating variables
R can be used to calculate new variables, subset from a given data
set, and for rearranging the format. In general, R prefers data to
be in the "long" format - this means fewer columns that specify a
variable (e.g. treatment, individual). The wide format would have
a separate column for each individual for each response variable.
```{r}
library(tidyr)
#We can use the pivot_wider function from tidyr to make the
#dataframe wider. What is unexpected about the output data
#frame?
data_wide <- pivot_wider(data = data,
                         names_from = `Poplar ID`,
                         values_from = c(A))

#Subsetting data can be done using brackets, [], or the
#subset() function. Beware that the subset function does not
#always behave as expected (see help file) and therefore
#should not be considered a reproducible way to subset data.
#Notice the difference between the two subsets with []. 
#What is changing?
data_2 <- data[data$A > 0, ]
data_3 <- data[, 1:3]
data_4 <- subset(data, data$A > 0)

#Next we calculate an estimate of gross photosynthesis from
#the data. At PARi = 0, A = respiration. Therefore
#A - respiration = gross photosynthesis.
data_5 <- data[data$`Poplar ID` == "1A" &
                 data$Rate == 0,]
data_5$Agross <- data_5$A - min(data_5$A)
```

#Data visualization in R
There are two major approaches to plotting in R, the base plot
function and ggplot. ggplot is by far easier to perfect than
base plot.
```{r}
#Install ggplot2
install.packages("ggplot2")

#Load the package
library(ggplot2)

#Let's read in some data
data <- read.csv("light_responses.csv", stringsAsFactors = FALSE)

#Let's look at the structure of the data file
str(data)

#Let's plot the data based on rate
ggplot(data = data, aes(x = PARi, y = A, colour = Rate)) +
  geom_point()

#That's a little too much data for the plot, so let's try something
#else
data <- split(data, data$Poplar.ID)

ggplot(data = data[[1]], aes(x = PARi, y = A, colour = Rate)) +
  geom_point()

#Now let's clean this up a bit to make it look nice
figure_1 <- ggplot(data = data[[1]], aes(x = PARi, y = A, colour = Rate)) +
  geom_point() +
  labs(x = expression("Irradiance ("*mu*mol~m^{-2}~s^{-1}*")"),
       y = expression("A ("*mu*mol~m^{-2}~s^{-1}*")")) +
  theme_bw() +
  theme(text = element_text(size = 14),
        legend.position = c(0.8, 0.25),
        legend.background = element_blank())

figure_1

#Now how do we get it out of R?
#Highlight and run all of these lines
#File will appear in working directory
jpeg("Figure 1.jpeg", height = 4, width = 4, res = 600, units = "in")
figure_1
dev.off()

#Look to see if it appeared
list.files()

#What about if we want to add a curve to the plot?
#Let's first pare the data just to the Rate = 0
data_test <- data[[1]][data[[1]]$Rate == 0, ]

#Next we use geom_smooth() - note that the default
#is to use loess smoothing, can change it to lm,
#can also specify the formula, slopes, intercepts, etc.
figure_2 <- ggplot(data = data_test, aes(x = PARi, y = A)) +
  geom_point() +
  geom_smooth() +
  labs(x = expression("Irradiance ("*mu*mol~m^{-2}~s^{-1}*")"),
       y = expression("A ("*mu*mol~m^{-2}~s^{-1}*")")) +
  theme_bw() +
  theme(text = element_text(size = 14))

figure_2

#What if we want to add a line with a slope = 0.06 (approximate
#initial slope of this light response) and intercept = -2?
#We can use geom_abline() for straight lines.
figure_3 <- ggplot(data = data_test, aes(x = PARi, y = A)) +
  geom_point() +
  geom_smooth() +
  geom_abline(slope = 0.06, intercept = -2) +
  labs(x = expression("Irradiance ("*mu*mol~m^{-2}~s^{-1}*")"),
       y = expression("A ("*mu*mol~m^{-2}~s^{-1}*")")) +
  theme_bw() +
  theme(text = element_text(size = 14))

figure_3

#Now we have three separate figure panels - what if they are all
#related and need to be in one figure? For this we can use the
#patchwork package. Patchwork provide a set of intuitive
#mathmatical operators for creating multipanel graphs. Below
#are a few examples of how to arrange plots in different ways.
library(patchwork)

figure_1 + figure_2 / figure_3 + 
  plot_annotation(tag_levels = "A")

figure_1 / (figure_2 | figure_3) + 
  plot_annotation(tag_levels = "A")

figure_1 / figure_2 / figure_3 + 
  plot_annotation(tag_levels = "1")

figure_1 + figure_2 + figure_3 + 
  plot_annotation(tag_levels = "1")

#What if you're feeling lazy and want a quick check on your data?
#Use the plot() function:
plot(A ~ gsw, data[[1]])
#This is nice when you need a fast visual check during your analysis

#Okay, but what if I want to use ggplot but am not too confident?
#Try ggplotgui!
install.packages("ggplotgui")
library(ggplotgui)

#ggplotgui gives you an interface with:
ggplot_shiny(data[[1]])
```


#Summarizing data in R
R can be used to readily summarize data - this can save
a substantial amount of time producing tables of summary
statistics for manuscripts. A very useful package for this
is the {dplyr} package.

{dplyr} provides the pipeline, %>%, which can simplify
code, and provides functions that aid in data summarization.
```{r}
library(dplyr)
data <- read.csv("light_responses.csv", stringsAsFactors = FALSE)

#group_by selects the variables with which to group
#In the summarize argument, you must use the "=".
data_summary <- data %>% 
  group_by(Poplar.ID, Rate) %>%
  summarize(A_mean = mean(A),
            A_se = sd(A) / sqrt(n()),
            gsw_mean = mean(gsw),
            gsw_se = sd(gsw) / sqrt(n()),
            slope = coef(lm(A ~ gsw))[[2]])
#Notice how you can run pretty much any function
#through summarize. Now let's print this out as a
#csv to make it easy to add into a manuscript
write.csv(data_summary, "data_summary.csv")

```

#Basic statistics in R
This section will cover linear regression, t tests, basic ANOVA,
and assumption checking
```{r}
#Let's read in some data
data <- read.csv("light_responses.csv", stringsAsFactors = FALSE)

#We will set rate as a factor for illustrating the ANOVA
data$Rate <- as.factor(data$Rate)

#To run ANOVAs, we will use the {car} package as it has a good
#set of tools for running ANOVAs
library(car)

#We are going to see the impact of gsw on Ci
plot(gsw ~ Ci, data[data$Poplar.ID == "1A", ])
#Looks like there is some grouping going on, probably due to
#the rate at which the light response was obtained

#WATCH OUT - summary(aov()) provides Type I sequential sum
#of squares, not Type III marginal sum of squares. We want
#the Type III SS, so we use the following function to get
#the relevant ANOVA summary:
model_1 <- Anova(aov(data = data,
               gsw ~ Ci * Rate),
               type = "III")

#Get the output:
model_1

#Check assumptions:
plot(aov(data = data,
               gsw ~ Ci * Rate))
#Data are not normal, probably should not use regular ANOVA

#We can also just try using the base ANOVA function
model_1 <- aov(data = data,
               gsw ~ Ci * Rate)
#We can take a look at the output for the example
summary(model_1)
#WATCH OUT - summary(aov()) provides Type I sequential sum
#of squares, not Type III marginal sum of squares. We want
#the Type III SS, so we use the following function to get
#the relevant ANOVA summary:
drop1(model_1, ~., test = "F")
#What is different between the summary() and drop1() options?

#What about if we take a regression approach instead?
model_2 <- lm(data = data, gsw ~ Ci * Rate)
plot(model_2)
summary(model_2)

#What differences are there between the summaries?
#Why might you choose one approach over the other?

#Since the data broke assumptions of our statistical models,
#let's use a robust approach. First we will convert Rate
#back to a numeric because there are issues in interactions
#between factors and doubles in the robust package
data$Rate <- as.numeric(levels(data$Rate)[data$Rate])
library(robust)
model_rob <- lmRob(gsw ~ Ci * Rate,
                   data = data)
summary(model_rob)
#What are the differences between the robust and standard
#tests?
```

