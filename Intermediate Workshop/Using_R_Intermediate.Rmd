---
title: 'Using R: Functions & Conditionals'
author: "Joseph R. Stinziano"
date: "09/01/2020"
output: html_document
---

#Using for loops
for loops are powerful for iterating analyses. We will start by
generating a random dataset, and from there run some iterated 
analyses. Note that random data generation as below is useful
for testing function behaviour.

```{r}
#First run set.seed to reproduce random examples
#Can be any number, but by assigning a single number,
#you ensure the random functions give the same output
#everytime you run them. Of course, this is only for 
#reproducibility.
set.seed(10)
#runif randomly samples a uniform distribution
Height <- runif(100, min = 0, max = 10)
StemDiameter <- runif(100, min = 0, max = 1)
Species <- c(rep("Pine", 25),
             rep("Avocado", 25),
             rep("Kale", 25),
             rep("Maple", 25)
             )
data <- data.frame(cbind(Height,
                            StemDiameter,
                            Species),
                      stringsAsFactors = FALSE)
data$Height <- as.numeric(data$Height)
data$StemDiameter <- as.numeric(data$StemDiameter)

#Suppose we want to run a linear model of Height ~ StemDiameter
#for each species. We need a way to separate the data
data <- split(data, data$Species)

#and an output...
output <- list()

#Use a for loop to run through index i, assign output
#to equivalent index
for(i in 1:length(data)){
  output[[i]] <- lm(Height ~ StemDiameter, data[[i]])
}

#Now let's see the results:
summary(output[[1]])

#Now let's say we need to add a new variable, Block,
#of which there is N = 5 for 5 different blocks.
#In this case, we can use a nested for loop
#We also need to pre-allocate a variable
for(i in 1:length(data)){
  data[[i]]$Block <- NA
  for(j in 1:(nrow(data[[i]]) / 5)){
    data[[i]]$Block[5 * j - 4] <- "A"
    data[[i]]$Block[5 * j - 3] <- "B"
    data[[i]]$Block[5 * j - 2] <- "C"
    data[[i]]$Block[5 * j - 1] <- "D"
    data[[i]]$Block[5 * j] <- "E"
  } #end j loop
} #end i loop

#Check that your indexing worked
data[[2]]$Block

#Is there another way we could have done this?

```

#When to use a list or a dataframe
Lists can be useful for speeding up data analyses - it is
relatively straightforward to convert dataframes to lists
and back in R. Let's look at an example where we add a new
variable, MAT (for mean annual temperature), with values
of 5, 7, 9, 11, and 13 that correspond to Blocks A, B, C,
D, and E, respectively.
```{r}
#Use the split function to split the dataframe into a
#list of dataframes based on block
data <- do.call("rbind", data)
data <- split(data, data$Block)

#Create a reference vector with the temperature to assign
MAT <- c(5, 7, 9, 11, 13)

#Use a for loop to automate assignment
for(i in 1:length(data)){
  data[[i]]$MAT <- MAT[i]
}

#Convert the list back to a dataframe
data <- do.call("rbind", data)

#Okay, now let's try this again, but we have to use the
#dataframe instead of a list
#First remove the variable MAT to avoid confusion
data$MAT <- NULL

#Need to add variable to dataframe
data$MAT <- NA
for(i in 1:nrow(data)){
  if(data$Block[i] == "A"){
    data$MAT[i] <- 5
  }
  if(data$Block[i] == "B"){
    data$MAT[i] <- 7
    }
  if(data$Block[i] == "C"){
    data$MAT[i] <- 9
    }
  if(data$Block[i] == "D"){
    data$MAT[i] <- 11
    }
  if(data$Block[i] == "E"){
    data$MAT[i] <- 13
  }
}
#Note the differences in the amount of code needed!
```

#Using conditionals
Conditionals are eponymous with their function: they are a tool
that subjects code to a set of conditions. These tools can be
used for subsetting analyses, bifurcating functions, running
analyses on subsets within a data object, and so on. The tools
include if-then, if-then-else-this, while, >, <, ==, <=, >=,
and !=, among others.
```{r}
#Let's say that we want to know the correlation between height
#and stem diameter only for blocks A and B

data_AB <- data[data$Block == "A" |
                  data$Block == "B", ]

#The | sign means OR. What happens if we use &?

data_AB_test <- data[data$Block == "A" &
                  data$Block == "B", ]

#There are no observations in the dataframe! Why?

#What if we combine A and B with c()?

data_AB_test <- data[data$Block == c("A", "B"), ]

#Unexpected behaviour! Lesson: always double check behaviour
#before building the next step. But there is a way to get this
#to work:

data_AB_test <- data[data$Block %in% c("A", "B"), ]

#What if we want CDE, but want to use not AB?

data_CDE <- data[data$Block != "A" &
                   data$Block != "B", ]

#Next let's subset the AB data for heights greater than or
#equal to the median height

data_AB_tophalf <- data_AB[data_AB$Height >= median(data_AB$Height), ]

#What about if we want heights less than the median, and stem
#diameters less than the mean?

data_AB_small <- data_AB[data_AB$Height < 
                           median(data_AB$Height) &
                           data_AB$StemDiameter <
                           mean(data_AB$StemDiameter), ]

#Now suppose there was a computer error in data collection such
#that the heights of C were halved, the stem diameter of D were
#doubled, and E was recorded correctly.
#We will use if statements to process this
boxplot(Height ~ Block, data_CDE)
for(i in 1:nrow(data_CDE)){
  if(data_CDE$Block[i] == "C"){
  data_CDE$Height[i] <- data_CDE$Height[i] * 2
  } else {
    data_CDE$StemDiameter[i] <- data_CDE$StemDiameter[i] / 2
  }
}

#Check the boxplot
boxplot(Height ~ Block, data_CDE)

#What about if pine had a further issue in that the Height
#was square-rooted before the other calculation errors, while
#being squared for the other species?
for(i in 1:nrow(data_CDE)){
  if(data_CDE$Species[i] == "Pine"){
    data_CDE$Height[i] <- data_CDE$Height[i] ^ 2
  } else {
    data_CDE$Height[i] <- sqrt(data_CDE$Height[i])
  }
}
#Check the boxplot
boxplot(Height ~ Block, data_CDE)
```

#Writing functions
At this point, we've covered the basic tools that are useful for
building functions. Now we can put them all together! We will
create a function that runs linear regressions on groups within
a dataframe, then extracts and outputs the slope and intercept.
```{r}
#function() sets up the arguments. Must be assigned to object
#arguments must be present within data
myfunction <- function(data, group,
                       x, y){
  #This ensure there are no issues with the code
  data$group <- data[, group]
  data$x <- data[, x]
  data$y <- data[, y]
  
  #Split the dataframe by group into a list of dataframes
  data <- split(data, data$group)
  
  #Create output lists
  output <- list()
  model <- list()
  
  #For loop to iterate
  for(i in 1:length(data)){
    output[[i]] <- data.frame(cbind(0, 0))
    colnames(output[[i]]) <- c("Intercept", "Slope")
    model[[i]] <- lm(y ~ x, data = data[[i]])
    output[[i]]$Intercept <- coef(model[[i]])[[1]]
    output[[i]]$Slope <- coef(model[[i]])[[2]]
    output[[i]]$Species <- names(data[i])
  }
  remove(model)
  data <- do.call("rbind", data)
  output <- do.call("rbind", output)
  return(output)
}

myoutput <- myfunction(data = data,
                       group = "Species",
                       x = "StemDiameter",
                       y = "Height")

#Besides loading a function into R as above, we can also load
#functions into R from an R script file using the source()
#function. First we will remove myfunction() from the global
#environment, then run source()
remove(myfunction)
source("example_function.R")
#See how the function appears in the global environment now?
```


#Fitting nonlinear functions to data
Since many biological responses are nonlinear, we will cover how
to fit nonlinear functions. Step 1 when fitting a nonlinear curve
is to ask yourself - can I linearize this? If you can, do that and
fit a linear regression - linear regressions can be fit with more
exact values than nonlinear curves in R. Step 2 is to create your
nonlinear function and then fit it.
```{r}
source("mynonlinearcurve.R")
data <- read.csv("light_responses.csv")

#First we split the data to one individual
data_1 <- data[data$Poplar.ID == "1A",]

#Next let's try the base nls() fitting function
model_1 <- nls(A ~ mynonlinearcurve(curvature,
                                    ksat,
                                    Q = PARi,
                                    qe) - Rd,
               data = data_1)
#Singular gradient matrix - this means your starting parameters
#are bad. Let's specify some. Since qe = quantum efficiency (ie
#the initial slope of the light response), we will estimate the
#initial slope
model_2 <- nls(A ~ mynonlinearcurve(curvature,
                                    ksat,
                                    Q = PARi,
                                    qe) - Rd,
               data = data_1,
               start = list(curvature = 0.85,
                            ksat = max(data_1$A),
                            qe = coef(lm(A ~ PARi, 
                                         data_1[data_1$PARi < 300,]))[[2]],
                            Rd = min(data_1$A)))
summary(model_2) #it works!

#Now let's try something else:
library(minpack.lm)
model_3 <- nlsLM(A ~ mynonlinearcurve(curvature,
                                    ksat,
                                    Q = PARi,
                                    qe) - Rd,
               data = data_1)
#this reached maximum number of iterations, let's change that!
model_4 <- nlsLM(A ~ mynonlinearcurve(curvature,
                                    ksat,
                                    Q = PARi,
                                    qe) - Rd,
               data = data_1,
               control = nls.lm.control(maxiter = 100))
summary(model_4)
#Gives NaNs warning, let's try specifying starting values
model_5 <- nlsLM(A ~ mynonlinearcurve(curvature,
                                    ksat,
                                    Q = PARi,
                                    qe) - Rd,
               data = data_1,
               start = list(curvature = 0.85,
                            ksat = max(data_1$A),
                            qe = coef(lm(A ~ PARi, 
                                         data_1[data_1$PARi < 300,]))[[2]],
                            Rd = min(data_1$A)))
summary(model_5) #Notice how the iteration problem went away?

#Okay, so what about plotting? This gets a little complicated
ggplot(data_1, aes(x = PARi, y = A)) +
  geom_point() +
  geom_smooth(method = "lm",
              formula = y ~ I(mynonlinearcurve(curvature = coef(model_5)[[1]],
                                             ksat = coef(model_5)[[2]],
                                             qe = coef(model_5)[[3]],
                                             Q = x) - coef(model_5)[[4]]))
#Notice the identity function I() - this is needed if there are
#coefficients outside the fitted function, like Rd in this case
```